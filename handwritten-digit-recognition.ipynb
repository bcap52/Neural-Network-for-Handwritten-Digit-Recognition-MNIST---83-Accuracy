{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt # pyplot is for showing images\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data=pd.read_csv('/kaggle/input/digit-recognizer/train.csv')#reads the file","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data=np.array(data)#converting data to numpy array\nm,n=data.shape#m are rows and n are columns\nnp.random.shuffle(data)\n#Development set\ndev_data=data[0:1000].T#transposing 1000 examples\ny_devdata=dev_data[0]#label\nx_devdata=dev_data[1:n]#actual data set \n\n#Training sets, remaining examples after 1000\ntrain_data=data[1000:m].T#transposing the rest of examples\ny_train=train_data[0]#labels, the first column\nx_train=train_data[1:n]#actual data set\nx_train=x_train/255\n_,m_train=x_train.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Parameters such as weights and biases\ndef init_parameters():\n    w1=np.random.rand(10, 784) -0.5\n    b1=np.random.rand(10,1)-0.5\n    w2=np.random.rand(10,10)-0.5\n    b2=np.random.rand(10,1)-0.5\n    return w1,b1,w2,b2\n    \ndef ReLU(z):#activation method for 0 to 1st layer\n    return np.maximum(0,z)\n\n\ndef softmax(z):#activation method 1st to 2nd\n    A = np.exp(z)/sum(np.exp(z))#collapses all rows(examples) into one and summed across all the columns which we divide with to each element which gives us the probability\n    return A\n\n#forward propogation\ndef forward_propogation(w1,b1,w2,b2,x):\n    z1=w1.dot(x)+b1\n    A1=ReLU(z1)\n    z2=w2.dot(A1)+b2\n    A2=softmax(z2)\n    return z1,A1,z2,A2\n\ndef one_hot(Y):\n    one_hot_Y = np.zeros((Y.size, Y.max() + 1))\n    one_hot_Y[np.arange(Y.size), Y] = 1\n    one_hot_Y = one_hot_Y.T\n    return one_hot_Y\n\ndef derivative_ReLU(z):\n    return z>0 #When z > 0: ReLU(z) = z, so derivative = 1\n\n#backwards propogation to find error\ndef back_propogation(z1,A1,z2,A2,w1,w2,y,x):\n    encoded_y=one_hot(y)\n    dz2=A2-encoded_y\n    dw2=1/m*dz2.dot(A1.T)\n    db2=1/m*np.sum(dz2)\n    dz1=w2.T.dot(dz2)*derivative_ReLU(z1)\n    dw1=1/m*dz1.dot(x.T)\n    db1=1/m*np.sum(dz1)\n    return dw1, db1, dw2, db2\n\n\n#updates parameters\ndef updata_param(w1,b1,w2,b2,dw2,db2,dw1,db1,alpha):\n    w1=w1-dw1*alpha #alpha is the learning rate of the training\n    b1=b1-db1*alpha\n    w2=w2-dw2*alpha \n    b2=b2-db2*alpha\n    return w1,b1,w2,b2\n\n\n    \n\n\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def get_predictions(A2):\n    return np.argmax(A2,0)\n    \n\n                     \ndef accuracy(predictions,y):\n    print(predictions,y)\n    return np.sum(predictions==y)/y.size\n\n\ndef gradient_desc(x, y, iterations, alpha):\n    w1, b1, w2, b2 = init_parameters()\n    for i in range(iterations):\n        z1, A1, z2, A2 = forward_propogation(w1, b1, w2, b2, x)\n        dw1, db1, dw2, db2 = back_propogation(z1,A1,z2,A2,w1,w2,y,x)\n        w1, b1, w2, b2 = updata_param(w1, b1, w2, b2, dw2, db2, dw1, db1, alpha)\n        if(i % 10 == 0):\n            print(\"iteration:\", i)\n            print(\"Accuracy:\", accuracy(get_predictions(A2), y))        \n    return w1, b1, w2, b2","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"w1,b1,w2,b2 =gradient_desc(x_train,y_train,500,0.10)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def make_predictions(x, w1, b1, w2, b2):\n    _, _, _, A2 = forward_propogation(w1, b1, w2, b2,x)\n    predictions = get_predictions(A2)\n    return predictions\n\ndef test_prediction(index, w1, b1, w2, b2):\n    current_image = x_train[:, index, None]\n    prediction = make_predictions(x_train[:, index, None], w1, b1, w2, b2)\n    label = y_train[index]\n    print(\"Prediction: \", prediction)\n    print(\"Label: \", label)\n    \n    current_image = current_image.reshape((28, 28)) * 255\n    plt.gray()\n    plt.imshow(current_image, interpolation='nearest')\n    plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_prediction(1042, w1, b1, w2, b2)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}